{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- [ ] latency summary에 추가하기\n",
    "- [ ] frame drop baseline performance 비교하는 figure 만들기; 기존 (using summary)\n",
    "- [ ] frame drop baseline들 backlog 증가 그래프 그리는 figure 만들기; 기존 (using data)\n",
    "- [ ] offloading baseline performance 비교하는 figure 만들기; fraction & accuracy & latency 비교; simulation에서 쓰던 형태 (using data & summary)\n",
    "- [ ] offloading baseline들 backlog 증가 그래프 그리는 figure 만들기; 기존 (using data)\n",
    "- [ ] multi agent 성능 비교 하는 figure 만들기\n",
    "- [ ] multi agent에서 각 source node의 backlog 증가 그래프 그려서 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, re, random\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import csv, json, ast  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### User define libraries\n",
    "import visualization as vis\n",
    "import data_manage as dm\n",
    "import lrlo as lrlo\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_value_from_latency(value_str):\n",
    "    return float(value_str.split('ms')[0].strip())\n",
    "\n",
    "def get_latency_exp(csv_path):\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['latency'] = df['latency'].apply(extract_value_from_latency)\n",
    "        return df\n",
    "        \n",
    "def get_backlog_exp(csv_path):\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return df[['sum', 'avg']]\n",
    "    \n",
    "def calculate_mean_latency(df):\n",
    "    mean_value = df['latency'].mean()\n",
    "    return mean_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = 'data/experiment'\n",
    "frame_drop_summary_path = 'data/summary/frame_dropping.csv'\n",
    "computation_offloading_summary_path = 'data/summary/computation_offloading.csv'\n",
    "multi_agent_summary_path = 'data/summary/multi_agent.csv'\n",
    "\n",
    "dataset_list = ['JN', 'JK', 'SD']\n",
    "exp_type_list = ['frame_dropping', 'computation_offloading', 'multi_agent']\n",
    "frame_drop_method_list = ['LRLO', 'Reducto', 'FrameHopper', 'CAO']\n",
    "computation_offloading_method_list = ['LRLO','JDPCRA', 'TLDOC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. get average latency value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JN\tframe_dropping\tLRLO\tmean latency: 1.6094955538603697\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 1.7579586878728815\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 26.951011964480607\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 24.657114469021245\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 2.1621528393556484\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 40.54465721888366\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 34.93247690288793\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 2.191208302552463\n",
      "JN\tframe_dropping\tLRLO\tmean latency: 1.7173717986659665\n",
      "JN\tframe_dropping\tReducto\tmean latency: 30.317076163746297\n",
      "JN\tframe_dropping\tReducto\tmean latency: 3.775056211800532\n",
      "JN\tframe_dropping\tFrameHopper\tmean latency: 28.386903660019968\n",
      "JN\tframe_dropping\tFrameHopper\tmean latency: 5.052483357297665\n",
      "JN\tframe_dropping\tCAO\tmean latency: 24.81877510508135\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 1.6094955538603697\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 1.7579586878728815\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 26.951011964480607\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 24.657114469021245\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 2.1621528393556484\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 40.54465721888366\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 34.93247690288793\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 2.191208302552463\n",
      "JN\tcomputation_offloading\tLRLO\tmean latency: 1.7173717986659665\n",
      "JN\tcomputation_offloading\tJDPCRA\tmean latency: 74.04049224794466\n",
      "JN\tcomputation_offloading\tTLDOC\tmean latency: 28.460393668267013\n",
      "JK\tframe_dropping\tLRLO\tmean latency: 36.371972419997064\n",
      "JK\tframe_dropping\tLRLO\tmean latency: 36.2569481867975\n",
      "JK\tframe_dropping\tLRLO\tmean latency: 14.230248414561727\n",
      "JK\tframe_dropping\tLRLO\tmean latency: 12.572770646494606\n",
      "JK\tframe_dropping\tReducto\tmean latency: 26.31403760327037\n",
      "JK\tframe_dropping\tReducto\tmean latency: 103.11667097414335\n",
      "JK\tframe_dropping\tFrameHopper\tmean latency: 13.28317102321319\n",
      "JK\tframe_dropping\tFrameHopper\tmean latency: 120.67269426939171\n",
      "JK\tframe_dropping\tCAO\tmean latency: 34.65867970541853\n",
      "JK\tcomputation_offloading\tLRLO\tmean latency: 36.371972419997064\n",
      "JK\tcomputation_offloading\tLRLO\tmean latency: 36.2569481867975\n",
      "JK\tcomputation_offloading\tLRLO\tmean latency: 14.230248414561727\n",
      "JK\tcomputation_offloading\tLRLO\tmean latency: 12.572770646494606\n",
      "JK\tcomputation_offloading\tJDPCRA\tmean latency: 43.36306842632235\n",
      "JK\tcomputation_offloading\tTLDOC\tmean latency: 26.514309261940443\n",
      "SD\tframe_dropping\tLRLO\tmean latency: 15.539509142870912\n",
      "SD\tframe_dropping\tLRLO\tmean latency: 40.82880103336092\n",
      "SD\tframe_dropping\tLRLO\tmean latency: 10.906684588032787\n",
      "SD\tframe_dropping\tLRLO\tmean latency: 38.76802474882311\n",
      "SD\tframe_dropping\tReducto\tmean latency: 127.44554511577273\n",
      "SD\tframe_dropping\tReducto\tmean latency: 21.12062380307368\n",
      "SD\tframe_dropping\tFrameHopper\tmean latency: 40.42860888142194\n",
      "SD\tframe_dropping\tFrameHopper\tmean latency: 27.088173931678508\n",
      "SD\tframe_dropping\tCAO\tmean latency: 34.858169696028426\n",
      "SD\tcomputation_offloading\tLRLO\tmean latency: 15.539509142870912\n",
      "SD\tcomputation_offloading\tLRLO\tmean latency: 40.82880103336092\n",
      "SD\tcomputation_offloading\tLRLO\tmean latency: 10.906684588032787\n",
      "SD\tcomputation_offloading\tLRLO\tmean latency: 38.76802474882311\n",
      "SD\tcomputation_offloading\tJDPCRA\tmean latency: 37.282154473444855\n",
      "SD\tcomputation_offloading\tTLDOC\tmean latency: 28.694640455028612\n"
     ]
    }
   ],
   "source": [
    "MS_TO_S = 1000\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    for exp_type in exp_type_list:\n",
    "        if exp_type == 'frame_dropping':\n",
    "            for method in frame_drop_method_list:\n",
    "                base_dir = f'{experiment_path}/{exp_type}/{method}_{dataset}'\n",
    "                \n",
    "                if method != 'CAO':\n",
    "                    subfolder_paths = [os.path.join(base_dir, name) for name in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, name))]\n",
    "                    for subfolder_path in subfolder_paths:\n",
    "                        latency_file_path = f'{subfolder_path}/latency/test job 1.csv'\n",
    "                        df = get_latency_exp(latency_file_path)\n",
    "                        mean_latency = calculate_mean_latency(df) / MS_TO_S\n",
    "                        print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}')\n",
    "                \n",
    "                else:\n",
    "                    latency_file_path = f'{base_dir}/latency/test job 1.csv'\n",
    "                    df = get_latency_exp(latency_file_path)\n",
    "                    mean_latency = calculate_mean_latency(df) / MS_TO_S\n",
    "                \n",
    "                    print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}')\n",
    "        \n",
    "        elif exp_type == 'computation_offloading':\n",
    "            for method in computation_offloading_method_list:\n",
    "                base_dir = f'{experiment_path}/{exp_type}/{method}_{dataset}'\n",
    "                \n",
    "                if method == 'LRLO':\n",
    "                    subfolder_paths = [os.path.join(base_dir, name) for name in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, name))]\n",
    "                    for subfolder_path in subfolder_paths:\n",
    "                        latency_file_path = f'{subfolder_path}/latency/test job 1.csv'\n",
    "                        df = get_latency_exp(latency_file_path)\n",
    "                        mean_latency = calculate_mean_latency(df) / MS_TO_S\n",
    "                        print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}')\n",
    "                \n",
    "                else:\n",
    "                    latency_file_path = f'{base_dir}/latency/test job 1.csv'\n",
    "                    df = get_latency_exp(latency_file_path)\n",
    "                    mean_latency = calculate_mean_latency(df) / MS_TO_S\n",
    "                \n",
    "                    print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv('data/csvs/experiment/collective_result.csv', skipinitialspace=True)\n",
    "exp_df = dm.revise_df(exp_df, 'divide', 'latency', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "datas = ['JK', 'SD', 'JN']\n",
    "exp_df_stack = exp_df.melt(id_vars=['method', 'data'], value_vars=['fraction', 'accuracy', 'latency'], var_name='Metric', value_name='Value')\n",
    "\n",
    "dm.df_info(exp_df_stack, 10)\n",
    "sns.set_palette(\"muted\")\n",
    "for i, data in enumerate(datas):\n",
    "    plt.figure()\n",
    "    df = exp_df_stack[exp_df_stack['data'] == data]\n",
    "\n",
    "    ax = sns.barplot(x='method', y='Value', hue='Metric', data=df[df['Metric'] != 'latency'], ci=None, width=0.5, edgecolor='0', palette=\"viridis\")\n",
    "    ax.set_xlabel('')\n",
    "    plt.ylabel('value (%)', fontsize=15) \n",
    "    \n",
    "    # Metric이 latency인 경우에만 오른쪽 축에 선 그래프를 그립니다.\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=12)  # x축 레이블 크기를 조정합니다.\n",
    "    \n",
    "    df_latency = df[df['Metric'] == 'latency']\n",
    "    if not df_latency.empty:\n",
    "        ax2 = ax.twinx()\n",
    "        sns.lineplot(x='method', y='Value', data=df_latency, marker='o', color=\"red\", ax=ax2, linewidth=2)\n",
    "        ax2.set_ylabel('latency (s)')\n",
    "\n",
    "    ax2.set_xlabel('')\n",
    "    plt.ylabel('Average latency (s)', fontsize=15) \n",
    "    #ax.set_xlabel('method')  # x축 라벨명칭 수정\n",
    "    ax2.tick_params(axis='x', rotation=45, labelsize=12)  # x축 레이블 크기를 조정합니다.\n",
    "    \n",
    "    ax.legend().remove()\n",
    "    #if data == 'JK':\n",
    "    #    ax.legend(('fraction', 'accuracy'), loc='lower center', bbox_to_anchor=(.5, 1.15), ncol=2, frameon=False, fontsize=14)\n",
    "    plt.tick_params(labelsize=12) \n",
    "    plt.tight_layout()  # 그래프 간 간격을 조정하여 겹침을 방지합니다\n",
    "    plt.savefig(SAVE_ROOT + \"exp_performance_\" + data + \".svg\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_latency_exp(df, length):\n",
    "    mean_value = df['latency'].sum() / len(df)\n",
    "    if length > len(df) + 5:    \n",
    "        sum_value = df['latency'].sum() \n",
    "        sum_value += (length-len(df)-5)*300000\n",
    "        mean_value = sum_value / length\n",
    "        #new_row = pd.DataFrame({'latency': [300000] * (length-len(df)-5)})\n",
    "        #df = pd.concat([df, new_row ], ignore_index=True) \n",
    "        #dm.df_info(df)\n",
    "    return mean_value, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 실험결과가 다 뽑고싶은 당신을 위해\n",
    "skip = False\n",
    "if not skip:\n",
    "    mean_latency_list = []\n",
    "    latency_df = {'JK':{}, 'SD':{}, 'JN':{}}\n",
    "    backlog_df = {'JK':{}, 'SD':{}, 'JN':{}}\n",
    "\n",
    "    data_dir_list = ['data/csvs/experiment/results_baseline/', 'data/csvs/experiment/results_LRLO/']\n",
    "    dataset = ['JK', 'SD', 'JN']\n",
    "            \n",
    "    for data_dir in data_dir_list:\n",
    "        for data in dataset:\n",
    "            folder_path = os.path.join(data_dir, data)\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for directory in dirs:\n",
    "                    if directory == 'latency':\n",
    "                        name = re.split(r\"[/\\\\]\",root)[-1]\n",
    "                        \n",
    "                        # parts = name.split(\"_\")   \n",
    "                        # prefix = parts[0] + \"_\" + name.split(\"_\")[3]\n",
    "                        if name.split(\"_\")[0] == 'LRLO':\n",
    "                            prefix = name.split(\"_\")[0] + \"_\" + name.split(\"_\")[3]\n",
    "                        else:\n",
    "                            if name.split(\"_\")[0] == 'frameHopper':\n",
    "                                prefix = \"FrameHopper\" + \"_\" + name.split(\"_\")[2]\n",
    "                            elif name.split(\"_\")[0] == 'reducto':\n",
    "                                prefix = \"Reducto\" + \"_\" + name.split(\"_\")[2]\n",
    "                        csv_path = os.path.join(root, directory, 'test job 1.csv')\n",
    "                        #if prefix in latency_df[data]:\n",
    "                        #    continue\n",
    "                        latency_df[data][prefix]= get_latency_exp(csv_path)\n",
    "                        path_path = os.path.join(root, 'path', 'path.csv')\n",
    "                        df = pd.read_csv(path_path)\n",
    "                        job_length = len(df)\n",
    "                        mean_latency, latency_df[data][prefix] = calculate_mean_latency_exp(latency_df[data][prefix], job_length)\n",
    "                        mean_latency_list.append([data+\"_\"+prefix, str(mean_latency)])\n",
    "                    elif directory == 'backlog':\n",
    "                        name = re.split(r\"[/\\\\]\",root)[-1]\n",
    "                        if name.split(\"_\")[0] == 'LRLO':\n",
    "                            prefix = name.split(\"_\")[0] + \"_\" + name.split(\"_\")[3]\n",
    "                        else:\n",
    "                            if name.split(\"_\")[0] == 'frameHopper':\n",
    "                                prefix = \"FrameHopper\" + \"_\" + name.split(\"_\")[2]\n",
    "                            elif name.split(\"_\")[0] == 'reducto':\n",
    "                                prefix = \"Reducto\" + \"_\" + name.split(\"_\")[2]\n",
    "                        csv_path = os.path.join(root, directory, 'total_backlog.csv')\n",
    "                        #if prefix in backlog_df[data]:\n",
    "                        #    print(\"in\")\n",
    "                        #    continue\n",
    "                        backlog_df[data][prefix] = get_backlog_exp(csv_path)\n",
    "\n",
    "                    #print(prefix)\n",
    "        \n",
    "    with open(\"data/csvs/experiment/mean_latency.csv\", \"w\",  newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(mean_latency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_list = ['frameHopper_0.7', 'frameHopper_0.9', 'reducto_0.7', 'reducto_0.9', 'LRLO_1000']\n",
    "#lrlo_list = ['LRLO_1000', 'LRLO_10000', 'LRLO_100000', 'LRLO_1000000', 'LRLO_10000000', 'LRLO_100000000']\n",
    "#for lrlo in lrlo_list:\n",
    "#    print(lrlo)\n",
    "key_list = ['FrameHopper_0.7', 'Reducto_0.7', \"LRLO_1000000\"]\n",
    "columns = ['avg', 'sum']\n",
    "target_data = 'JK'\n",
    "sns.set_palette(\"muted\")\n",
    "for data in dataset:\n",
    "    if data != target_data:\n",
    "        continue\n",
    "    data_df = backlog_df[data]\n",
    "    for column in columns:\n",
    "        #print(column)\n",
    "        flag = True\n",
    "        for key, df in data_df.items():\n",
    "            #print(data_df.keys())\n",
    "            if key_list[-1] not in data_df.keys():\n",
    "                flag = False\n",
    "                break\n",
    "            #print(key)\n",
    "            if key not in key_list:\n",
    "                continue\n",
    "            # x_values = np.arange(0, len(df) * 0.1, 0.1)\n",
    "            df.reindex(np.arange(0, len(df) * 0.1, 0.1))\n",
    "            sampled_df = dm.get_sampled_df(df, 10)\n",
    "            #x_values = np.arange(0, len(sampled_df) * 0.1, 0.1)\n",
    "            #sns.lineplot(x=latency_masking_df.index, y=latency_masking_df[column], alpha=0.5)\n",
    "            if key[0] == 'L':\n",
    "                key = \"LRLO\"\n",
    "            sns.lineplot(x=sampled_df.index, y=sampled_df[column], label=key, lw=1.5, palette=\"Muted\")\n",
    "            #sns.lineplot(x=latency_unmasking_df.index, y=latency_unmasking_df[column], alpha=0.5)\n",
    "        if flag:\n",
    "            print(\"dataset\", data)\n",
    "            plt.xlim(0, 2800)\n",
    "            plt.ylim(0, 300000000)\n",
    "            plt.xlabel('Time (s)', fontsize=16)  \n",
    "            plt.ylabel('Backlog (B)', fontsize=16) \n",
    "            plt.tick_params(labelsize=12) \n",
    "            plt.legend(loc='upper left', fontsize=12) \n",
    "            plt.savefig(SAVE_ROOT+\"exp_backlog_\"+column+\".pdf\") \n",
    "            idx += 1\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
