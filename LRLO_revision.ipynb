{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- [ ] latency summary에 추가하기\n",
    "- [ ] frame drop baseline performance 비교하는 figure 만들기; 기존 (using summary)\n",
    "- [ ] frame drop baseline들 backlog 증가 그래프 그리는 figure 만들기; 기존 (using data)\n",
    "- [ ] offloading baseline performance 비교하는 figure 만들기; fraction & accuracy & latency 비교; simulation에서 쓰던 형태 (using data & summary)\n",
    "- [ ] offloading baseline들 backlog 증가 그래프 그리는 figure 만들기; 기존 (using data)\n",
    "- [ ] multi agent 성능 비교 하는 figure 만들기\n",
    "- [ ] multi agent에서 각 source node의 backlog 증가 그래프 그려서 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, re, random\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import csv, json, ast  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### User define libraries\n",
    "import visualization as vis\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_value_from_latency(value_str):\n",
    "    return float(value_str.split('ms')[0].strip())\n",
    "\n",
    "def get_latency_exp(csv_path):\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['latency'] = df['latency'].apply(extract_value_from_latency)\n",
    "        return df\n",
    "        \n",
    "def get_backlog_exp(csv_path):\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return df[['sum', 'avg']]\n",
    "    \n",
    "# def calculate_mean_latency(df):\n",
    "#     mean_value = df['latency'].mean()\n",
    "#     return mean_value\n",
    "\n",
    "def calculate_mean_latency(df, length):\n",
    "    mean_value = df['latency'].mean()\n",
    "    if length > len(df) + 5:    \n",
    "        sum_value = df['latency'].sum() \n",
    "        sum_value += (length-len(df)-5)*300000\n",
    "        mean_value = sum_value / length\n",
    "        \n",
    "    return mean_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = 'data/experiment'\n",
    "frame_drop_summary_path = 'data/summary/frame_dropping.csv'\n",
    "computation_offloading_summary_path = 'data/summary/computation_offloading.csv'\n",
    "multi_agent_summary_path = 'data/summary/multi_agent.csv'\n",
    "\n",
    "dataset_list = ['JN', 'JK', 'SD']\n",
    "exp_type_list = ['frame_dropping', 'computation_offloading', 'multi_agent']\n",
    "frame_drop_method_list = ['LRLO', 'Reducto', 'FrameHopper', 'CAO']\n",
    "computation_offloading_method_list = ['LRLO','JDPCRA', 'TLDOC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. get average latency value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_TO_S = 1000\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    for exp_type in exp_type_list:\n",
    "        if exp_type == 'frame_dropping':\n",
    "            for method in frame_drop_method_list:\n",
    "                base_dir = f'{experiment_path}/{exp_type}/{method}_{dataset}'\n",
    "                \n",
    "                if method != 'CAO':\n",
    "                    subfolder_paths = [os.path.join(base_dir, name) for name in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, name))]\n",
    "                    for subfolder_path in subfolder_paths:\n",
    "                        path_df = pd.read_csv(f'{subfolder_path}/path/path.csv')\n",
    "                        job_length = len(path_df)\n",
    "                        latency_file_path = f'{subfolder_path}/latency/test job 1.csv'\n",
    "                        df = get_latency_exp(latency_file_path)\n",
    "                        mean_latency = calculate_mean_latency(df, job_length) / MS_TO_S\n",
    "                        print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}\\t ({latency_file_path})')\n",
    "                \n",
    "                else:\n",
    "                    path_df = pd.read_csv(f'{base_dir}/path/path.csv')\n",
    "                    job_length = len(path_df)\n",
    "                    latency_file_path = f'{base_dir}/latency/test job 1.csv'\n",
    "                    df = get_latency_exp(latency_file_path)\n",
    "                    mean_latency = calculate_mean_latency(df, job_length) / MS_TO_S\n",
    "                    print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}')\n",
    "        \n",
    "        elif exp_type == 'computation_offloading':\n",
    "            for method in computation_offloading_method_list:\n",
    "                base_dir = f'{experiment_path}/{exp_type}/{method}_{dataset}'\n",
    "                \n",
    "                if method == 'LRLO':\n",
    "                    subfolder_paths = [os.path.join(base_dir, name) for name in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, name))]\n",
    "                    for subfolder_path in subfolder_paths:\n",
    "                        path_df = pd.read_csv(f'{subfolder_path}/path/path.csv')\n",
    "                        job_length = len(path_df)\n",
    "                        latency_file_path = f'{subfolder_path}/latency/test job 1.csv'\n",
    "                        df = get_latency_exp(latency_file_path)\n",
    "                        mean_latency = calculate_mean_latency(df, job_length) / MS_TO_S\n",
    "                        print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}\\t ({latency_file_path})')\n",
    "                else:\n",
    "                    path_df = pd.read_csv(f'{base_dir}/path/path.csv')\n",
    "                    job_length = len(path_df)\n",
    "                    latency_file_path = f'{base_dir}/latency/test job 1.csv'\n",
    "                    df = get_latency_exp(latency_file_path)\n",
    "                    mean_latency = calculate_mean_latency(df, job_length) / MS_TO_S\n",
    "                \n",
    "                    print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}')\n",
    "                    \n",
    "        # else:\n",
    "        #     base_dir = f'{experiment_path}/{exp_type}/LRLO(MA)_{dataset}'\n",
    "        #     latency_file_path_1 = f'{base_dir}/latency/test job 1.csv'\n",
    "        #     latency_file_path_2 = f'{base_dir}/latency/test job 2.csv'    \n",
    "            \n",
    "        #     df = get_latency_exp(latency_file_path_1)\n",
    "        #     mean_latency = calculate_mean_latency(df) / MS_TO_S\n",
    "        #     print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}\\t ({latency_file_path_1})')\n",
    "            \n",
    "        #     df = get_latency_exp(latency_file_path_2)\n",
    "        #     mean_latency = calculate_mean_latency(df) / MS_TO_S\n",
    "        #     print(f'{dataset}\\t{exp_type}\\t{method}\\tmean latency: {mean_latency}\\t ({latency_file_path_2})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Frame drop] performance 비교 (코드 완성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df = pd.read_csv(frame_drop_summary_path, skipinitialspace=True)\n",
    "drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "axis_size = 13\n",
    "label_size = 15\n",
    "\n",
    "drop_df['method_with_target'] = drop_df.apply(\n",
    "    lambda row: \"LRLO(Ours)\" if row['method'] == \"LRLO\" else (f\"{row['method']}({row['target_f1']})\" if not pd.isna(row['target_f1']) else row['method']),\n",
    "    axis=1\n",
    ")\n",
    "datasets = drop_df['dataset'].unique()\n",
    "\n",
    "for dataset in datasets:\n",
    "    subset = drop_df[drop_df['dataset'] == dataset]\n",
    "    \n",
    "    melted_df = subset.melt(id_vars=['method_with_target'], value_vars=['f1_score', 'fraction'], \n",
    "                            var_name='Metric', value_name='Value')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2, 6))\n",
    "    \n",
    "    sns.barplot(data=melted_df, x='method_with_target', y='Value', hue='Metric', palette=\"viridis\", ax=ax,  width=0.6, edgecolor='0')\n",
    "    ax2 = ax.twinx()\n",
    "    sns.lineplot(data=subset, x='method_with_target', y='latency', color=\"red\", marker=\"o\", label='latency', ax=ax2)\n",
    "\n",
    "    # 축과 레이블 설정\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Value (%)', fontsize=label_size)\n",
    "    ax2.set_ylabel('Average latency (s)', fontsize=label_size)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=35, labelsize=axis_size)\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{y * 100:.0f}'))  # 예: 0.1 -> 10\n",
    "    \n",
    "    # y축 tick 폰트 크기 조정\n",
    "    ax.tick_params(axis='y', labelsize=axis_size)  \n",
    "    ax2.tick_params(axis='y', labelsize=axis_size) \n",
    "\n",
    "    # 범례 폰트 크기 조정\n",
    "    ax.legend(loc='upper left', fontsize=axis_size)\n",
    "    ax2.legend(loc='upper right', fontsize=axis_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [Frame Drop] Backlog Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 backlog df 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backlog_df_dict = {\n",
    "    'JN': {\n",
    "        'LRLO(Ours)': [],\n",
    "        'Reducto(0.7)': None,\n",
    "        'Reducto(0.9)': None,\n",
    "        'FrameHopper(0.7)': None,\n",
    "        'FrameHopper(0.9)': None,\n",
    "        'CAO': None\n",
    "    },\n",
    "    'JK': {\n",
    "        'LRLO': [],\n",
    "        'Reducto(0.7)': None,\n",
    "        'Reducto(0.9)': None,\n",
    "        'FrameHopper(0.7)': None,\n",
    "        'FrameHopper(0.9)': None,\n",
    "        'CAO': None\n",
    "    },\n",
    "    'SD': {\n",
    "        'LRLO': [],\n",
    "        'Reducto(0.7)': None,\n",
    "        'Reducto(0.9)': None,\n",
    "        'FrameHopper(0.7)': None,\n",
    "        'FrameHopper(0.9)': None,\n",
    "        'CAO': None\n",
    "    }\n",
    "}\n",
    "\n",
    "for dataset in datasets:\n",
    "    for method in frame_drop_method_list:\n",
    "        if method == 'CAO':\n",
    "            backlog_path = f'{experiment_path}/frame_dropping/{method}_{dataset}'\n",
    "        elif method == 'LRLO':\n",
    "            s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 실험결과가 다 뽑고싶은 당신을 위해\n",
    "skip = False\n",
    "if not skip:\n",
    "    mean_latency_list = []\n",
    "    latency_df = {'JK':{}, 'SD':{}, 'JN':{}}\n",
    "    backlog_df = {'JK':{}, 'SD':{}, 'JN':{}}\n",
    "\n",
    "    data_dir_list = ['data/csvs/experiment/results_baseline/', 'data/csvs/experiment/results_LRLO/']\n",
    "    dataset = ['JK', 'SD', 'JN']\n",
    "            \n",
    "    for data_dir in data_dir_list:\n",
    "        for data in dataset:\n",
    "            folder_path = os.path.join(data_dir, data)\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for directory in dirs:\n",
    "                    if directory == 'latency':\n",
    "                        name = re.split(r\"[/\\\\]\",root)[-1]\n",
    "                        \n",
    "                        # parts = name.split(\"_\")   \n",
    "                        # prefix = parts[0] + \"_\" + name.split(\"_\")[3]\n",
    "                        if name.split(\"_\")[0] == 'LRLO':\n",
    "                            prefix = name.split(\"_\")[0] + \"_\" + name.split(\"_\")[3]\n",
    "                        else:\n",
    "                            if name.split(\"_\")[0] == 'frameHopper':\n",
    "                                prefix = \"FrameHopper\" + \"_\" + name.split(\"_\")[2]\n",
    "                            elif name.split(\"_\")[0] == 'reducto':\n",
    "                                prefix = \"Reducto\" + \"_\" + name.split(\"_\")[2]\n",
    "                        csv_path = os.path.join(root, directory, 'test job 1.csv')\n",
    "                        #if prefix in latency_df[data]:\n",
    "                        #    continue\n",
    "                        latency_df[data][prefix]= get_latency_exp(csv_path)\n",
    "                        path_path = os.path.join(root, 'path', 'path.csv')\n",
    "                        df = pd.read_csv(path_path)\n",
    "                        job_length = len(df)\n",
    "                        mean_latency, latency_df[data][prefix] = calculate_mean_latency_exp(latency_df[data][prefix], job_length)\n",
    "                        mean_latency_list.append([data+\"_\"+prefix, str(mean_latency)])\n",
    "                    elif directory == 'backlog':\n",
    "                        name = re.split(r\"[/\\\\]\",root)[-1]\n",
    "                        if name.split(\"_\")[0] == 'LRLO':\n",
    "                            prefix = name.split(\"_\")[0] + \"_\" + name.split(\"_\")[3]\n",
    "                        else:\n",
    "                            if name.split(\"_\")[0] == 'frameHopper':\n",
    "                                prefix = \"FrameHopper\" + \"_\" + name.split(\"_\")[2]\n",
    "                            elif name.split(\"_\")[0] == 'reducto':\n",
    "                                prefix = \"Reducto\" + \"_\" + name.split(\"_\")[2]\n",
    "                        csv_path = os.path.join(root, directory, 'total_backlog.csv')\n",
    "                        #if prefix in backlog_df[data]:\n",
    "                        #    print(\"in\")\n",
    "                        #    continue\n",
    "                        backlog_df[data][prefix] = get_backlog_exp(csv_path)\n",
    "\n",
    "                    #print(prefix)\n",
    "        \n",
    "    with open(\"data/csvs/experiment/mean_latency.csv\", \"w\",  newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(mean_latency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_list = ['frameHopper_0.7', 'frameHopper_0.9', 'reducto_0.7', 'reducto_0.9', 'LRLO_1000']\n",
    "#lrlo_list = ['LRLO_1000', 'LRLO_10000', 'LRLO_100000', 'LRLO_1000000', 'LRLO_10000000', 'LRLO_100000000']\n",
    "#for lrlo in lrlo_list:\n",
    "#    print(lrlo)\n",
    "key_list = ['FrameHopper_0.7', 'Reducto_0.7', \"LRLO_1000000\"]\n",
    "columns = ['avg', 'sum']\n",
    "target_data = 'JK'\n",
    "sns.set_palette(\"muted\")\n",
    "for data in dataset:\n",
    "    if data != target_data:\n",
    "        continue\n",
    "    data_df = backlog_df[data]\n",
    "    for column in columns:\n",
    "        #print(column)\n",
    "        flag = True\n",
    "        for key, df in data_df.items():\n",
    "            #print(data_df.keys())\n",
    "            if key_list[-1] not in data_df.keys():\n",
    "                flag = False\n",
    "                break\n",
    "            #print(key)\n",
    "            if key not in key_list:\n",
    "                continue\n",
    "            # x_values = np.arange(0, len(df) * 0.1, 0.1)\n",
    "            df.reindex(np.arange(0, len(df) * 0.1, 0.1))\n",
    "            sampled_df = dm.get_sampled_df(df, 10)\n",
    "            #x_values = np.arange(0, len(sampled_df) * 0.1, 0.1)\n",
    "            #sns.lineplot(x=latency_masking_df.index, y=latency_masking_df[column], alpha=0.5)\n",
    "            if key[0] == 'L':\n",
    "                key = \"LRLO\"\n",
    "            sns.lineplot(x=sampled_df.index, y=sampled_df[column], label=key, lw=1.5, palette=\"Muted\")\n",
    "            #sns.lineplot(x=latency_unmasking_df.index, y=latency_unmasking_df[column], alpha=0.5)\n",
    "        if flag:\n",
    "            print(\"dataset\", data)\n",
    "            plt.xlim(0, 2800)\n",
    "            plt.ylim(0, 300000000)\n",
    "            plt.xlabel('Time (s)', fontsize=16)  \n",
    "            plt.ylabel('Backlog (B)', fontsize=16) \n",
    "            plt.tick_params(labelsize=12) \n",
    "            plt.legend(loc='upper left', fontsize=12) \n",
    "            plt.savefig(SAVE_ROOT+\"exp_backlog_\"+column+\".pdf\") \n",
    "            idx += 1\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
