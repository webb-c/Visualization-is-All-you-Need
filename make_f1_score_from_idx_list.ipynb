{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, re, random\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import csv\n",
    "import ast  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_F1(origin_labels, comparison_labels, threshold=0.5):\n",
    "    if len(origin_labels) == 0 and len(comparison_labels) == 0:\n",
    "        return 1.0  \n",
    "    \n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    \n",
    "    if len(origin_labels) == 0:\n",
    "        FP = len(comparison_labels)\n",
    "        return 0.0\n",
    "    \n",
    "    if len(comparison_labels) == 0:\n",
    "        FP = len(origin_labels)\n",
    "        return 0.0\n",
    "    \n",
    "    for fPred in origin_labels:\n",
    "        fc, fx, fy, fw, fh = fPred\n",
    "        fArea = fw * fh\n",
    "        \n",
    "        maxIOU = 0.0\n",
    "        for sPred in comparison_labels:\n",
    "            sc, sx, sy, sw, sh = sPred\n",
    "            \n",
    "            if fc != sc:\n",
    "                continue\n",
    "\n",
    "            sArea = sw * sh\n",
    "            \n",
    "            interArea = max(0, min(fx + fw, sx + sw) - max(fx, sx)) * max(0, min(fy + fh, sy + sh) - max(fy, sy))\n",
    "            unionArea = fArea + sArea - interArea\n",
    "            IOU = interArea / unionArea\n",
    "            maxIOU = max(maxIOU, IOU)\n",
    "        \n",
    "        if maxIOU >= threshold:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    \n",
    "    FN = len(comparison_labels) - TP\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    F1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    \n",
    "    F1 = min(1.0, F1)\n",
    "    \n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(file_path):\n",
    "    \"\"\"주어진 file path에 있는 detection file을 parsing하여, list로 변환한다.\n",
    "    Args:\n",
    "        file_path (string): detection file path\n",
    "    Returns:\n",
    "        List: detected object lists\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file :\n",
    "        label_list = []\n",
    "        for line in file :\n",
    "            line = line.strip().split()\n",
    "            x, y, w, h = map(float, line[1:5])\n",
    "            c = int(line[0])\n",
    "            label_list.append((c, x, y, w, h))\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F1(origin_file_path, RL_file_path) :\n",
    "    origin_labels = parse_results(origin_file_path)\n",
    "    RL_labels = parse_results(RL_file_path)\n",
    "    \n",
    "    return cal_F1(origin_labels, RL_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(origin_idx_list, RL_idx_list, dataset):\n",
    "    \"\"\"원본 frame idx들의 list와 RL이 선택한 frame idx들의 list를 입력받아, RL에 의해 변화한 F1 score를 계산한다.\n",
    "    Args:\n",
    "        origin_idx_list (_type_): _description_\n",
    "        RL_idx_list (_type_): _description_\n",
    "        detect_path (_type_): _description_\n",
    "    \"\"\"\n",
    "    total_f1_score = 0\n",
    "    num_frame = 0\n",
    "    \n",
    "    detect_path = f\"data/detect/{dataset}/labels/\"\n",
    "    detect_file_list = os.listdir(detect_path)\n",
    "    \n",
    "    exist_idx_list = [int(file.split(\"_\")[-1].split(\".\")[0]) for file in detect_file_list]\n",
    "    exist_idx_list.sort()\n",
    "    \n",
    "    for i in range(len(origin_idx_list)):\n",
    "        origin_idx, RL_idx = origin_idx_list[i], RL_idx_list[i]\n",
    "        \n",
    "        if origin_idx == RL_idx:\n",
    "            if origin_idx in exist_idx_list:\n",
    "                total_f1_score += 1.0\n",
    "                num_frame += 1\n",
    "            \n",
    "        else:\n",
    "            if origin_idx in exist_idx_list and RL_idx in exist_idx_list:\n",
    "                origin_file = f\"{detect_path}/{dataset}_{origin_idx}.txt\"\n",
    "                RL_file = f\"{detect_path}/{dataset}_{RL_idx}.txt\"\n",
    "                total_f1_score += get_F1(origin_file, RL_file)\n",
    "                num_frame += 1\n",
    "                \n",
    "            elif origin_idx in exist_idx_list and RL_idx not in exist_idx_list:\n",
    "                total_f1_score += 0.0\n",
    "                num_frame += 1\n",
    "                \n",
    "            elif origin_idx not in exist_idx_list and RL_idx in exist_idx_list:\n",
    "                total_f1_score += 0.0\n",
    "                num_frame += 1\n",
    "        \n",
    "        \n",
    "    avg_f1_score = total_f1_score / num_frame\n",
    "        \n",
    "    return avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JN\t frame_dropping\t LRLO : 0.32470349454244013\n",
      "JN\t frame_dropping\t LRLO : 0.32000339575046066\n",
      "JN\t frame_dropping\t LRLO : 0.3057213182894893\n",
      "JN\t frame_dropping\t LRLO : 0.3028041007449667\n",
      "JN\t frame_dropping\t LRLO : 0.30035356226086135\n",
      "JN\t frame_dropping\t LRLO : 0.47654870739977007\n",
      "JN\t frame_dropping\t LRLO : 0.6235436412089876\n",
      "JN\t frame_dropping\t LRLO : 0.7474236777715043\n",
      "JN\t frame_dropping\t LRLO : 0.7552359621055276\n",
      "JN\t frame_dropping\t FrameHopper : 0.46250388247167457\n",
      "JN\t frame_dropping\t FrameHopper : 0.7975932554554471\n",
      "\n",
      "JN\t computation_offloading\t LRLO : 0.26135298468167595\n",
      "JN\t computation_offloading\t LRLO : 0.2597950219507427\n",
      "JN\t computation_offloading\t LRLO : 0.2560617473370816\n",
      "JN\t computation_offloading\t LRLO : 0.26777526854165407\n",
      "JN\t computation_offloading\t LRLO : 0.24784502422587745\n",
      "JN\t computation_offloading\t LRLO : 0.368003192428919\n",
      "JN\t computation_offloading\t LRLO : 0.4489417126526282\n",
      "JN\t computation_offloading\t LRLO : 0.5571810935373\n",
      "JN\t computation_offloading\t LRLO : 0.5629686410765995\n",
      "JN\t computation_offloading\t JDPCRA : 0.5629686410765995\n",
      "JN\t computation_offloading\t TLDOC : 0.5629686410765995\n",
      "\n",
      "JK\t frame_dropping\t LRLO : 0.7411038614982896\n",
      "JK\t frame_dropping\t LRLO : 0.7481606666687266\n",
      "JK\t frame_dropping\t LRLO : 0.8313775231366393\n",
      "JK\t frame_dropping\t LRLO : 0.9106914801186371\n",
      "JK\t frame_dropping\t FrameHopper : 0.959284313929575\n",
      "JK\t frame_dropping\t FrameHopper : 0.9144532073888534\n",
      "\n",
      "JK\t computation_offloading\t LRLO : 0.7286798587068027\n",
      "JK\t computation_offloading\t LRLO : 0.7343145041304291\n",
      "JK\t computation_offloading\t LRLO : 0.8144161322235413\n",
      "JK\t computation_offloading\t LRLO : 0.8840281918958196\n",
      "JK\t computation_offloading\t JDPCRA : 0.9472893246264438\n",
      "JK\t computation_offloading\t TLDOC : 0.9472893246264438\n",
      "\n",
      "SD\t frame_dropping\t LRLO : 0.5691245645825207\n",
      "SD\t frame_dropping\t LRLO : 0.5675051530835741\n",
      "SD\t frame_dropping\t LRLO : 0.6581463186223436\n",
      "SD\t frame_dropping\t LRLO : 0.6919901402795212\n",
      "SD\t frame_dropping\t FrameHopper : 0.9447383900134595\n",
      "SD\t frame_dropping\t FrameHopper : 0.7165228197640581\n",
      "\n",
      "SD\t computation_offloading\t LRLO : 0.5419170609215463\n",
      "SD\t computation_offloading\t LRLO : 0.5409407725606126\n",
      "SD\t computation_offloading\t LRLO : 0.6184981398825544\n",
      "SD\t computation_offloading\t LRLO : 0.6486135361779433\n",
      "SD\t computation_offloading\t JDPCRA : 0.8377683544266616\n",
      "SD\t computation_offloading\t TLDOC : 0.8377683544266616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_path = 'data/experiment'\n",
    "\n",
    "dataset_list = ['JN', 'JK', 'SD']\n",
    "exp_type_list = ['frame_dropping', 'computation_offloading'] #, 'multi_agent']\n",
    "frame_drop_method_list = ['LRLO', 'FrameHopper']\n",
    "computation_offloading_drop_method_list = ['LRLO','JDPCRA', 'TLDOC']\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    for exp_type in exp_type_list:\n",
    "        if exp_type == 'frame_dropping':\n",
    "            for method in frame_drop_method_list:\n",
    "                config_file = f'{experiment_path}/{exp_type}/{method}_{dataset}/test_config.csv'\n",
    "                \n",
    "                with open(config_file, mode='r', newline='') as file:\n",
    "                    reader = csv.reader(file)\n",
    "                    list_data = []  # Store converted lists from each line\n",
    "                    \n",
    "                    for row in reader:\n",
    "                        for item in row:\n",
    "                            # Check if the item matches the list pattern (e.g., \"[1, 2, ...]\")\n",
    "                            if item.startswith('[') and item.endswith(']'):\n",
    "                                # Safely evaluate the string to convert it into a list\n",
    "                                list_converted = ast.literal_eval(item)\n",
    "                                list_data.append(list_converted)\n",
    "                                \n",
    "                    for RL_idx_list in list_data:\n",
    "                        RL_idx_list = [ i+1 for i in RL_idx_list]\n",
    "                        origin_idx_list = [ i+1 for i in range (len(RL_idx_list)) ]\n",
    "                        f1_score = get_f1_score(origin_idx_list, RL_idx_list, dataset)\n",
    "                        print(f'{dataset}\\t {exp_type}\\t {method} : {f1_score}')\n",
    "        else:\n",
    "            for method in computation_offloading_drop_method_list:\n",
    "                config_file = f'{experiment_path}/{exp_type}/{method}_{dataset}/test_config.csv'\n",
    "                \n",
    "                with open(config_file, mode='r', newline='') as file:\n",
    "                    reader = csv.reader(file)\n",
    "                    list_data = []  # Store converted lists from each line\n",
    "                    \n",
    "                    for row in reader:\n",
    "                        for item in row:\n",
    "                            # Check if the item matches the list pattern (e.g., \"[1, 2, ...]\")\n",
    "                            if item.startswith('[') and item.endswith(']'):\n",
    "                                # Safely evaluate the string to convert it into a list\n",
    "                                list_converted = ast.literal_eval(item)\n",
    "                                list_data.append(list_converted)\n",
    "                                \n",
    "                    for RL_idx_list in list_data:\n",
    "                        origin_idx_list = [ i+1 for i in range (len(RL_idx_list)) ]\n",
    "                        f1_score = get_f1_score(origin_idx_list, RL_idx_list, dataset)\n",
    "                        print(f'{dataset}\\t {exp_type}\\t {method} : {f1_score}')\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
